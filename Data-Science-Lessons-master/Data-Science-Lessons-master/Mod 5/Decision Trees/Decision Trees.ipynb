{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> From Decision Trees to Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## <center> Growing Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> <b>Contact Lens Type Determination</b> <br><br>\n",
    "<center><img src='decision_tree.png' height=700 width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Two algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### <center> ID3\n",
    "<center>Iterative Dichotomiser 3 (Classification only) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### <center> CART   </center>\n",
    "<center>Classification and Regression Trees </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center> Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='entropy.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"entropy_formula.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "-((1/2)*np.log(1/2)+(1/2)*np.log(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center> Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>The reduction of uncertainty about Y given an additional piece of information X about Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='ig_formula.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Building a Decision Tree From Scratch (ID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame()\n",
    "df['Older Than 30'] = [False, True, True, False, True]\n",
    "df['Occupation'] = ['Doctor', 'Lawyer', 'Truck Driver', 'Doctor', 'Truck Driver']\n",
    "df['Income Over 80000'] = [True, True, False, False, True]\n",
    "df['Approved'] = [True, True, False, False, False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Number approved/not approved\n",
    "df['Approved'].value_counts()\n",
    "approved = df[df['Approved']==True]\n",
    "not_approved = df[df['Approved']==False]\n",
    "total = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Entropy of parent node\n",
    "entropy_parent = -((len(approved)/total)*np.log(len(approved)/total)+\n",
    "                   (len(not_approved)/total)*np.log(len(not_approved)/total))\n",
    "entropy_parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Entropy and Information Gain of Age\n",
    "older = df[df['Older Than 30']==True]\n",
    "younger = df[df['Older Than 30']==False]\n",
    "\n",
    "weight_older = len(older)/total\n",
    "weight_younger = len(younger)/total\n",
    "\n",
    "older_approved = older[older['Approved']==True]\n",
    "older_not_approved = older[older['Approved']==False]\n",
    "younger_approved = younger[younger['Approved']==True]\n",
    "younger_not_approved = older[older['Approved']==False]\n",
    "\n",
    "entropy_older = -((len(older_approved)/len(older))*np.log(len(older_approved)/len(older))\n",
    "                  +(len(older_not_approved)/len(older))*np.log(len(older_not_approved)/len(older)))\n",
    "\n",
    "entropy_younger = -((len(younger_approved)/len(younger))*np.log(len(younger_approved)/len(younger))\n",
    "                  +(len(younger_not_approved)/len(younger))*np.log(len(younger_not_approved)/len(younger)))\n",
    "\n",
    "entropy_age = entropy_older*weight_older + entropy_younger*weight_younger\n",
    "ig_age = entropy_parent - entropy_age\n",
    "print('Information Gain (Age):', ig_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(count_true, count_false, count_total):\n",
    "    true = (count_true/count_total)*np.log(count_true/count_total) if count_true > 0 else 0\n",
    "    false = (count_false/count_total)*np.log(count_false/count_total) if count_false > 0 else 0\n",
    "    return -(true + false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Entropy and Information Gain of Occupation\n",
    "occupations = list(df['Occupation'].value_counts().index)\n",
    "occupation_dfs = [df[df['Occupation']==i] for i in occupations]\n",
    "occupation_weights = [len(i)/total for i in occupation_dfs]\n",
    "occupation_approved = [i[i['Approved']==True] for i in occupation_dfs]\n",
    "occupation_not_approved = [i[i['Approved']==False] for i in occupation_dfs]\n",
    "\n",
    "entropy_occupation = np.sum([entropy(len(x), len(y), len(occupation))*weight for x,y,occupation,weight \n",
    "                                         in zip(occupation_approved, occupation_not_approved, \n",
    "                                                        occupation_dfs, occupation_weights)])\n",
    "                                                                                         \n",
    "ig_occupation = entropy_parent - entropy_occupation\n",
    "print('Information Gain (Occupation):', ig_occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Entropy and Information Gain of Income\n",
    "incomes = list(df['Income Over 80000'].value_counts().index)\n",
    "income_dfs = [df[df['Income Over 80000']==i] for i in incomes]\n",
    "income_weights = [len(i)/total for i in income_dfs]\n",
    "income_approved = [i[i['Approved']==True] for i in income_dfs]\n",
    "income_not_approved = [i[i['Approved']==False] for i in income_dfs]\n",
    "\n",
    "entropy_income = np.sum([entropy(len(x), len(y), len(income))*weight for x,y,income,weight\n",
    "                                         in zip(income_approved, income_not_approved, \n",
    "                                                        income_dfs, income_weights)])\n",
    "                                                                                         \n",
    "ig_income = entropy_parent - entropy_income\n",
    "print('Information Gain (Income):', ig_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print('Information Gains')\n",
    "p=[print(i,\":\",j) for i,j in zip(['Age','Occupation','Income'],[ig_age, ig_occupation, ig_income])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for occupation in occupations:\n",
    "    ## calculate parent entropy\n",
    "    o_df = df[df['Occupation']==occupation]\n",
    "    o_total = len(o_df)\n",
    "    true = len(o_df[o_df['Approved']==True])\n",
    "    false = len(o_df[o_df['Approved']==False])\n",
    "    p_entropy = entropy(true,false,o_total)\n",
    "    ## calculate children entropy\n",
    "    ## Age\n",
    "    ages = list(o_df['Older Than 30'].value_counts().index)\n",
    "    age_dfs = [o_df[o_df['Older Than 30']==i] for i in ages]\n",
    "    age_weights = [len(i)/o_total for i in age_dfs]\n",
    "    age_approved = [i[i['Approved']==True] for i in age_dfs]\n",
    "    age_not_approved = [i[i['Approved']==False] for i in age_dfs]\n",
    "    entropy_age = np.sum([entropy(len(x), len(y), len(age))*weight for x,y,age,weight\n",
    "                                     in zip(age_approved, age_not_approved, \n",
    "                                                    age_dfs, age_weights)])                                                                  \n",
    "    ig_age = entropy_parent - entropy_age\n",
    "    ## Income\n",
    "    incomes = list(o_df['Income Over 80000'].value_counts().index)\n",
    "    income_dfs = [o_df[o_df['Income Over 80000']==i] for i in incomes]\n",
    "    income_weights = [len(i)/o_total for i in income_dfs]\n",
    "    income_approved = [i[i['Approved']==True] for i in income_dfs]\n",
    "    income_not_approved = [i[i['Approved']==False] for i in income_dfs]\n",
    "    entropy_income = np.sum([entropy(len(x), len(y), len(income))*weight for x,y,income,weight\n",
    "                                     in zip(income_approved, income_not_approved, \n",
    "                                                    income_dfs, income_weights)])                                                                  \n",
    "    ig_income = entropy_parent - entropy_income\n",
    "    print(occupation, '--', 'Age' if ig_age>ig_income else 'Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## convert features to categories\n",
    "for i in df.columns:\n",
    "    df[i] = df[i].astype('category').cat.codes\n",
    "## fit model\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf.fit(df.drop('Approved',axis=1), df['Approved'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_tree(clf,node_ids=False,\n",
    "              impurity=False,\n",
    "              label=None,\n",
    "              filled=True,\n",
    "              feature_names=df.drop('Approved',axis=1).columns, \n",
    "              class_names=['Approved','Not Approved'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Using the data in data_scientists.csv, build a decision tree from scratch to predict whether or not someone is a Data Scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Then, build the tree in Python and compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Steps:\n",
    "    - Find the entropy of the target.\n",
    "    - Find the weighted entropy for each feature.\n",
    "    - Calculate the information gain for each feature.\n",
    "    - Select the feature with the highest IG as the root node.\n",
    "    - Repeat process, finding entropy of root node, then entropy of children, and compare IG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center>CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Similar to ID3, except for the formula used in determining branches. <br>\n",
    "Newer, more common algorithm, default in DecisionTreeClassifer/DecisionTreeRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"gini_formula.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Decision Trees for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression, make_classification\n",
    "X,y = make_regression(n_samples=10,n_features=2, n_informative=2, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "reg_df = pd.DataFrame(X)\n",
    "reg_df.columns = ['X'+str(i+1) for i in range(len(reg_df.columns))]\n",
    "reg_df['target'] = y\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "reg_clf = DecisionTreeRegressor().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_vals = np.linspace(-3,3,100)\n",
    "y_vals = np.linspace(-3,3,100)\n",
    "preds = []\n",
    "for x_ in x_vals:\n",
    "    for y_ in y_vals:\n",
    "        pred = reg_clf.predict(np.array([x_, y_]).reshape(1,-1))\n",
    "        preds.append(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "set(y)==set(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center> In regression, decision trees can only predict values in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Tuning Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> <b>Parameters</b><br><br>\n",
    "<center> <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">DecisionTreeClassifier Documentation</a>\n",
    "<center> <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\">DecisionTreeRegressor Documentation</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## make dataset\n",
    "X,y = make_regression(n_samples=1000,n_features=10, n_informative=8, random_state=47)\n",
    "## train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15, random_state=47)\n",
    "## fit base model\n",
    "base_model = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "## train/test accuracy\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print('Train MSE:', mean_squared_error(y_train, base_model.predict(X_train)))\n",
    "print('Train R2:', r2_score(y_train, base_model.predict(X_train)));print('')\n",
    "print('Test MSE:', mean_squared_error(y_test, base_model.predict(X_test)))\n",
    "print('Test R2:', r2_score(y_test, base_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'max_depth':[5,10,20], \n",
    "              'min_samples_split':[0.5,1.0,2,3],\n",
    "              'max_features':['auto',None],\n",
    "              'min_impurity_decrease':[0,0.5,0.75]\n",
    "             }\n",
    "dtr = DecisionTreeRegressor()\n",
    "grid_search_model = GridSearchCV(dtr, params,scoring='r2', verbose=1)\n",
    "grid_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_model.best_estimator_\n",
    "print('Train MSE:', mean_squared_error(y_train, best_model.predict(X_train)))\n",
    "print('Train R2:', r2_score(y_train, best_model.predict(X_train)));print('')\n",
    "print('Test MSE:', mean_squared_error(y_test, best_model.predict(X_test)))\n",
    "print('Test R2:', r2_score(y_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use the data in disease_prediction.csv to build a model to predict whether or not a person is likely to have a disease.<br><br>\n",
    "- Choose the appropriate measures of model success and scoring metrics to fit the best model - \n",
    " <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\">Scoring metrics</a> <br><br>\n",
    "- Utitlize GridSearchCV to tune your decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
