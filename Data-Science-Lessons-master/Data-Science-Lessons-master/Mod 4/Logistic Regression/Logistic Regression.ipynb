{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You should be able to:\n",
    "- Implement logistic regression\n",
    "- Understand confusion matrices\n",
    "- Understand AUC and ROC curves\n",
    "- Select the best classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## generate data\n",
    "X,y = make_classification(n_samples=100, n_features=1,n_informative=1,n_redundant=0, n_classes=2, n_clusters_per_class=1, random_state=4)\n",
    "X = X+3\n",
    "df = pd.DataFrame(X.tolist(),columns=['X1'])\n",
    "df['target']=y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## visualize data\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## simple linear regression\n",
    "model = sm.OLS(y,sm.add_constant(X)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## regression line\n",
    "plt.scatter(X, y)\n",
    "X_lin = np.linspace(1,5,100)\n",
    "plt.plot(X_lin, model.predict(sm.add_constant(X_lin)), color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e**(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_lin = np.linspace(-20,20,100)\n",
    "plt.plot(X_lin, sigmoid(X_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## comparing different sigmoid functions\n",
    "X_lin = np.linspace(-20,20,100)\n",
    "for i in range(1,5):\n",
    "    for j in range(-4,5,2):\n",
    "        plt.plot(X_lin, sigmoid(X_lin*i+j))\n",
    "        plt.title('i='+str(i))\n",
    "        plt.legend(['-4','-2','0','2','4'],title='j')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Based on probability and maximum likelihood estimation (MLE)\n",
    "- Instead of predicting continuous values, predicts binary class labels\n",
    "- Performs classification by predicting either a 0 or 1 for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## fit logistic model\n",
    "model = LogisticRegression().fit(X,y)\n",
    "plt.scatter(X,y)\n",
    "X_lin = np.linspace(1,5,100)\n",
    "plt.plot(X_lin,model.predict(X_lin.reshape(-1,1)),color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,y)\n",
    "X_lin = np.linspace(0,6,100)\n",
    "plt.plot(X_lin, sigmoid(X_lin*model.coef_+model.intercept_)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### With two features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X,y = make_classification(class_sep=1.5,n_samples=100, n_features=2,n_informative=2,n_redundant=0, n_classes=2, n_clusters_per_class=1, random_state=222)\n",
    "X = X+3\n",
    "df = pd.DataFrame(X.tolist(),columns=['X1','X2'])\n",
    "df['target']=y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x='X1',y='X2',c='target',cmap='winter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs').fit(X,y)\n",
    "print('Coefficients:',model.coef_[0])\n",
    "print('Intecept:',model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_lin=np.linspace(-1,7,100)\n",
    "b = model.intercept_\n",
    "w = model.coef_[0]\n",
    "y_lin = (w[0]*X_lin+b)/(-1*w[1])\n",
    "plt.scatter(X[:,0], X[:,1],c=y,cmap='winter')\n",
    "plt.plot(X_lin, y_lin,color='orange')\n",
    "plt.ylim(-2,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing logistic models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X,y = make_classification(flip_y=.25,n_clusters_per_class=1,class_sep=0.5, n_samples=1000, n_features=4,n_informative=2,n_classes=2, random_state=44477)\n",
    "X = X+3\n",
    "df = pd.DataFrame(X.tolist(),columns=['X1','X2','X3','X4'])\n",
    "df['target']=y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## base model\n",
    "base_model = LogisticRegression().fit(X_train,y_train)\n",
    "print('Train accuracy:',accuracy_score(y_train,base_model.predict(X_train)))\n",
    "print('Test accuracy:',accuracy_score(y_test,base_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## RFE to find best n features\n",
    "from sklearn.feature_selection import RFE\n",
    "i_,train_acc, test_acc, models = [],[],[],[]\n",
    "for i in range(1,X.shape[1]):\n",
    "    i_.append(i)\n",
    "    selector = RFE(LogisticRegression(solver='lbfgs'),i)\n",
    "    selector.fit(X_train,y_train)\n",
    "    train_acc.append(accuracy_score(y_train,selector.predict(X_train)))\n",
    "    test_acc.append(accuracy_score(y_test,selector.predict(X_test)))\n",
    "    models.append(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(i_,train_acc)\n",
    "plt.plot(i_,test_acc)\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_acc), print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='confusion_matrix.png' height=1000 width=1000>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "fig.set_size_inches(20,5)\n",
    "sns.heatmap(confusion_matrix(y_test, models[0].predict(X_test)), ax=ax1, annot=True,annot_kws={\"size\": 16},cmap='coolwarm');ax1.set_title('1 feature')\n",
    "sns.heatmap(confusion_matrix(y_test, models[1].predict(X_test)), ax=ax2, annot=True,annot_kws={\"size\": 16},cmap='coolwarm');ax2.set_title('2 features')\n",
    "sns.heatmap(confusion_matrix(y_test, models[2].predict(X_test)), ax=ax3, annot=True,annot_kws={\"size\": 16},cmap='coolwarm');ax3.set_title('3 features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## finding best feature\n",
    "model = RFE(LogisticRegression(solver='lbfgs'),1).fit(X_train,y_train)\n",
    "model.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Sensitivity and Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> Sensitivity = True Positives / Total Positives <br>\n",
    "Specificity = True Negatives / Total Negatives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> Typically inversely proportional to each other - when we increase one, we decrease the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### <center> What's more important to minimize - false positives or false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, model.predict(X_test)), annot=True,annot_kws={\"size\": 16},cmap='coolwarm', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sensitivity = \n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "specificity = \n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get probabilities for each predictions\n",
    "probs = model.predict_proba(X_test)\n",
    "probs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get probabilities for predicting 1\n",
    "positive_probs = probs[:,1]\n",
    "positive_probs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting custom threshold for positive predictions\n",
    "threshold = 0.50\n",
    "decisions = [1 if i>threshold else 0 for i in positive_probs]\n",
    "decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "thresholds = [0.15, 0.25, 0.50, 0.75, 0.85]\n",
    "spec,sens = [],[]\n",
    "for t in thresholds:\n",
    "    decisions = [1 if i>t else 0 for i in positive_probs]\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, decisions).ravel()\n",
    "    sens.append(tp/(tp+fn))\n",
    "    spec.append(tn/(tn+fp))\n",
    "results['Threshold'] = thresholds\n",
    "results['Sensitivity'] = sens\n",
    "results['Specificity'] = spec\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> AUC and ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> ROC curves show the tradeoff between specificity and sensitivity.\n",
    "<center> Specificity is on the y-axis while 1-sensitivity is on the x-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> AUC is the area under the ROC curve. <br>\n",
    "A model has a perfect fit if it has an AUC of 1.0.<br>\n",
    "A naive model (random guessing) will have an AUC of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_roc(x,y,model):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    y_pred_probs = model.predict_proba(x)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred_probs)\n",
    "    sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "    print('AUC:',auc(fpr, tpr))\n",
    "    plt.plot(fpr, tpr, color='orangered',lw=2, label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)])\n",
    "    plt.xticks([i/20.0 for i in range(21)])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_roc(X_test,y_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X,y = make_classification(weights=[0.02],n_clusters_per_class=1,class_sep=2, n_samples=1000, n_features=4,n_informative=2,n_classes=2, random_state=44)\n",
    "X = X+3\n",
    "df = pd.DataFrame(X.tolist(),columns=['X1','X2','X3','X4'])\n",
    "df['target']=y\n",
    "print(df['target'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs').fit(X_train,y_train)\n",
    "print('Test Accuracy:', accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "sns.heatmap(cm, annot=True,annot_kws={\"size\": 16},cmap='coolwarm', fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "base_sensitivity = cm[1][1]/(cm[1][1]+cm[0][1])\n",
    "base_specificity = cm[0][0]/(cm[0][0]+cm[1][0])\n",
    "print('Sensitivity:', base_sensitivity)\n",
    "print('Specificity:', base_specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=47)\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train)\n",
    "model = LogisticRegression(solver='lbfgs').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(y_train_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, model.predict(X_test)).ravel()\n",
    "print('Before SMOTE')\n",
    "print('-------------')\n",
    "print('Sensitivity:',base_sensitivity)\n",
    "print('Specificity:',base_specificity);print()\n",
    "print('After SMOTE')\n",
    "print('-------------')\n",
    "print('Sensitivity:',tp/(tp+fn))\n",
    "print('Specificity:',tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> Activity\n",
    "Using the data found in <i>loan_data.csv</i>, build a logistic regression model to predict whether future loan applicants will default on their loan or not. <br>\n",
    "Then, use your best model to make predictions on new customers whose data can be found in <i>new_customers.csv</i>.<br><br>\n",
    "<b>Hints</b>\n",
    "- Categorical variables can be included in logistic regression, just make sure you transform them first\n",
    "- Remember to always scale your data if your features are in different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
